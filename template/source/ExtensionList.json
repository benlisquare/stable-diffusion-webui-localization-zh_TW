{
  "Aesthetic Gradients": "Aesthetic Gradients",
  "Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.": "Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.",
  "Dreambooth": "Dreambooth",
  "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.": "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.",
  "training-picker": "training-picker",
  "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.": "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.",
  "Dataset Tag Editor": "Dataset Tag Editor",
  "Feature-rich UI tab that allows image viewing, search-filtering and editing.": "Feature-rich UI tab that allows image viewing, search-filtering and editing.",
  "DreamArtist": "DreamArtist",
  "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.": "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.",
  "WD 1.4 Tagger": "WD 1.4 Tagger",
  "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.": "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.",
  "Hypernetwork-Monkeypatch-Extension": "Hypernetwork-Monkeypatch-Extension",
  "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.": "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.",
  "Custom Diffusion": "Custom Diffusion",
  "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.": "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.",
  "Smart Process": "Smart Process",
  "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.": "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.",
  "Embeddings editor": "Embeddings editor",
  "Allows you to manually edit textual inversion embeddings using sliders.": "Allows you to manually edit textual inversion embeddings using sliders.",
  "embedding-inspector": "embedding-inspector",
  "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.": "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.",
  "Merge Board": "Merge Board",
  "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.": "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.",
  "Model Converter": "Model Converter",
  "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.": "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.",
  "Kohya-ss Additional Networks": "Kohya-ss Additional Networks",
  "Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.": "Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.",
  "Merge Block Weighted": "Merge Block Weighted",
  "Merge models with separate rate for each 25 U-Net block (input, middle, output).": "Merge models with separate rate for each 25 U-Net block (input, middle, output).",
  "Embedding Merge": "Embedding Merge",
  "Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.": "Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.",
  "SuperMerger": "SuperMerger",
  "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.": "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.",
  "LoRA Block Weight": "LoRA Block Weight",
  "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.": "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.",
  "Image browser": "Image browser",
  "Provides an interface to browse created images in the web browser.": "Provides an interface to browse created images in the web browser.",
  "Inspiration": "Inspiration",
  "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.": "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.",
  "Artists to study": "Artists to study",
  "Shows a gallery of generated pictures by artists separated into categories.": "Shows a gallery of generated pictures by artists separated into categories.",
  "Prompt Gallery": "Prompt Gallery",
  "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.": "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.",
  "Infinity Grid Generator": "Infinity Grid Generator",
  "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.": "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.",
  "Config-Presets": "Config-Presets",
  "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.": "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.",
  "Preset Utilities": "Preset Utilities",
  "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)": "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)",
  "openOutpaint extension": "openOutpaint extension",
  "A tab with the full openOutpaint UI. Run with the --api flag.": "A tab with the full openOutpaint UI. Run with the --api flag.",
  "quick-css": "quick-css",
  "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.": "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.",
  "Aspect Ratio selector": "Aspect Ratio selector",
  "Adds image aspect ratio selector buttons.": "Adds image aspect ratio selector buttons.",
  "Catppuccin Theme": "Catppuccin Theme",
  "Adds various custom themes": "Adds various custom themes",
  "Kitchen Theme": "Kitchen Theme",
  "Custom Theme.": "Custom Theme.",
  "Bilingual Localization": "Bilingual Localization",
  "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.": "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.",
  "Dynamic Prompts": "Dynamic Prompts",
  "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.": "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.",
  "Unprompted": "Unprompted",
  "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.": "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.",
  "StylePile": "StylePile",
  "An easy way to mix and match elements to prompts that affect the style of the result.": "An easy way to mix and match elements to prompts that affect the style of the result.",
  "Booru tag autocompletion": "Booru tag autocompletion",
  "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.": "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.",
  "novelai-2-local-prompt": "novelai-2-local-prompt",
  "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.": "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.",
  "tokenizer": "tokenizer",
  "Adds a tab that lets you preview how CLIP model would tokenize your text.": "Adds a tab that lets you preview how CLIP model would tokenize your text.",
  "Randomize": "Randomize",
  "Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize": "Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize",
  "conditioning-highres-fix": "conditioning-highres-fix",
  "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt": "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt",
  "model-keyword": "model-keyword",
  "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.": "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.",
  "Prompt Generator": "Prompt Generator",
  "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.": "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.",
  "Promptgen": "Promptgen",
  "Use transformers models to generate prompts.": "Use transformers models to generate prompts.",
  "text2prompt": "text2prompt",
  "Generates anime tags using databases and models for tokenizing.": "Generates anime tags using databases and models for tokenizing.",
  "Prompt Translator": "Prompt Translator",
  "A integrated translator for translating prompts to English using Deepl or Baidu.": "A integrated translator for translating prompts to English using Deepl or Baidu.",
  "Deforum": "Deforum",
  "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.": "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.",
  "Animator": "Animator",
  "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.": "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.",
  "gif2gif": "gif2gif",
  "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif": "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif",
  "Video Loopback": "Video Loopback",
  "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.": "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.",
  "seed travel": "seed travel",
  "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.": "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.",
  "shift-attention": "shift-attention",
  "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.": "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.",
  "prompt travel": "prompt travel",
  "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.": "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.",
  "Steps Animation": "Steps Animation",
  "Create animation sequence from denoised intermediate steps.": "Create animation sequence from denoised intermediate steps.",
  "auto-sd-paint-ext": "auto-sd-paint-ext",
  "Krita Plugin.": "Krita Plugin.",
  "Detection Detailer": "Detection Detailer",
  "An object detection and auto-mask extension for Stable Diffusion web UI.": "An object detection and auto-mask extension for Stable Diffusion web UI.",
  "Batch Face Swap": "Batch Face Swap",
  "Automatically detects faces and replaces them.": "Automatically detects faces and replaces them.",
  "Depth Maps": "Depth Maps",
  "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.": "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.",
  "multi-subject-render": "multi-subject-render",
  "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.": "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.",
  "depthmap2mask": "depthmap2mask",
  "Create masks for img2img based on a depth estimation made by MiDaS.": "Create masks for img2img based on a depth estimation made by MiDaS.",
  "ABG_extension": "ABG_extension",
  "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.": "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.",
  "Pixelization": "Pixelization",
  "Using pre-trained models, produce pixel art out of images in the extras tab.": "Using pre-trained models, produce pixel art out of images in the extras tab.",
  "haku-img": "haku-img",
  "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.": "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.",
  "Asymmetric Tiling": "Asymmetric Tiling",
  "An always visible script extension to configure seamless image tiling independently for the X and Y axes.": "An always visible script extension to configure seamless image tiling independently for the X and Y axes.",
  "Latent Mirroring": "Latent Mirroring",
  "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections": "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections",
  "Sonar": "Sonar",
  "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.": "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.",
  "Depth Image I/O": "Depth Image I/O",
  "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.": "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.",
  "Ultimate SD Upscale": "Ultimate SD Upscale",
  "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).": "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).",
  "Fusion": "Fusion",
  "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.": "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.",
  "Dynamic Thresholding": "Dynamic Thresholding",
  "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.": "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.",
  "anti-burn": "anti-burn",
  "Smoothing generated images by skipping a few very last steps and averaging together some images before them.": "Smoothing generated images by skipping a few very last steps and averaging together some images before them.",
  "sd-webui-controlnet": "sd-webui-controlnet",
  "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.": "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.",
  "Latent Couple": "Latent Couple",
  "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts.": "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts.",
  "Composable LoRA": "Composable LoRA",
  "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.": "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.",
  "Auto TLS-HTTPS": "Auto TLS-HTTPS",
  "Allows you to easily, or even completely automatically start using HTTPS.": "Allows you to easily, or even completely automatically start using HTTPS.",
  "booru2prompt": "booru2prompt",
  "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.": "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.",
  "Gelbooru Prompt": "Gelbooru Prompt",
  "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui": "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui",
  "NSFW checker": "NSFW checker",
  "Replaces NSFW images with black.": "Replaces NSFW images with black.",
  "Diffusion Defender": "Diffusion Defender",
  "Prompt blacklist, find and replace, for semi-private and public instances.": "Prompt blacklist, find and replace, for semi-private and public instances.",
  "DH Patch": "DH Patch",
  "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.": "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.",
  "Riffusion": "Riffusion",
  "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.": "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.",
  "Save Intermediate Images": "Save Intermediate Images",
  "Save intermediate images during the sampling process. You can also make videos from the intermediate images.": "Save intermediate images during the sampling process. You can also make videos from the intermediate images.",
  "Add image number to grid": "Add image number to grid",
  "Add the image's number to its picture in the grid.": "Add the image's number to its picture in the grid.",
  "Multiple Hypernetworks": "Multiple Hypernetworks",
  "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.": "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.",
  "System Info": "System Info",
  "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.": "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.",
  "OpenPose Editor": "OpenPose Editor",
  "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.": "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.",
  "Stable Horde Worker": "Stable Horde Worker",
  "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.": "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.",
  "Stable Horde Client": "Stable Horde Client",
  "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.": "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.",
  "Discord Rich Presence": "Discord Rich Presence",
  "Provides connection to Discord RPC, showing a fancy table in the user profile.": "Provides connection to Discord RPC, showing a fancy table in the user profile.",
  "mine-diffusion": "mine-diffusion",
  "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.": "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.",
  "Aesthetic Image Scorer": "Aesthetic Image Scorer",
  "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer": "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer",
  "Aesthetic Scorer": "Aesthetic Scorer",
  "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.": "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.",
  "cafe-aesthetic": "cafe-aesthetic",
  "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.": "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.",
  "Clip Interrogator": "Clip Interrogator",
  "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.": "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.",
  "Visualize Cross-Attention": "Visualize Cross-Attention",
  "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.": "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.",
  "DAAM": "DAAM",
  "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.": "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.",
  "Dump U-Net": "Dump U-Net",
  "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547": "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547",
  "posex": "posex",
  "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.": "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.",
  "LLuL": "LLuL",
  "Local Latent Upscaler. Target an area to selectively enhance details.": "Local Latent Upscaler. Target an area to selectively enhance details.",
  "CFG-Schedule-for-Automatic1111-SD": "CFG-Schedule-for-Automatic1111-SD",
  "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.": "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.",
  "a1111-sd-webui-locon": "a1111-sd-webui-locon",
  "An extension for loading LoCon networks in webui.": "An extension for loading LoCon networks in webui.",
  "ebsynth_utility": "ebsynth_utility",
  "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.": "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.",
  "VRAM Estimator": "VRAM Estimator",
  "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.": "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.",
  "MultiDiffusion with Tiled VAE": "MultiDiffusion with Tiled VAE",
  "Seamless Image Fusion, along with vram efficient tiled vae script.": "Seamless Image Fusion, along with vram efficient tiled vae script.",
  "3D Model Loader": "3D Model Loader",
  "Load your 3D model/animation inside webui, then send screenshot to txt2img or img2img to ControlNet.": "Load your 3D model/animation inside webui, then send screenshot to txt2img or img2img to ControlNet.",
  "Corridor Crawler Outpainting": "Corridor Crawler Outpainting",
  "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.": "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.",
  "Panorama Viewer": "Panorama Viewer",
  "Provides a tab to display equirectangular images in interactive 3d-view.": "Provides a tab to display equirectangular images in interactive 3d-view.",
  "db-storage1111": "db-storage1111",
  "Allows to store pictures and their metadata in a database. (supports MongoDB)": "Allows to store pictures and their metadata in a database. (supports MongoDB)",
  "stable-diffusion-webui-rembg": "stable-diffusion-webui-rembg",
  "Removes backgrounds from pictures.": "Removes backgrounds from pictures.",
  "sd-webui-tunnels": "sd-webui-tunnels",
  "Add alternatives to the default tunneling methods. (including cloudflared)": "Add alternatives to the default tunneling methods. (including cloudflared)",
  "3D Openpose Editor": "3D Openpose Editor",
  "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.": "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.",
  "sd-webui-enable-checker": "sd-webui-enable-checker",
  "Switch background color by clicking the Enable buttons in SD Web UI": "Switch background color by clicking the Enable buttons in SD Web UI",
  "stable-diffusion-webui-state": "stable-diffusion-webui-state",
  "Preserves the UI state after reload/restart.": "Preserves the UI state after reload/restart.",
  "ModelScope text2video": "ModelScope text2video",
  "Implementation of ModelScope text2video using only Auto1111 webui dependencies.": "Implementation of ModelScope text2video using only Auto1111 webui dependencies.",
  "Aspect Ratio Helper": "Aspect Ratio Helper",
  "Easily scale dimensions while retaining the same aspect ratio.": "Easily scale dimensions while retaining the same aspect ratio.",
  "zh_CN Localization": "zh_CN Localization",
  "Simplified Chinese localization, recommend using with Bilingual Localization.": "Simplified Chinese localization, recommend using with Bilingual Localization.",
  "zh_TW Localization": "zh_TW Localization",
  "Traditional Chinese localization": "Traditional Chinese localization",
  "ko_KR Localization": "ko_KR Localization",
  "Korean localization": "Korean localization",
  "th_TH Localization": "th_TH Localization",
  "Thai localization": "Thai localization",
  "es_ES Localization": "es_ES Localization",
  "Spanish localization": "Spanish localization",
  "it_IT Localization": "it_IT Localization",
  "Italian localization": "Italian localization",
  "de_DE Localization": "de_DE Localization",
  "German localization": "German localization",
  "ja_JP Localization": "ja_JP Localization",
  "Japanese localization": "Japanese localization",
  "pt_BR Localization": "pt_BR Localization",
  "Brazillian portuguese localization": "Brazillian portuguese localization",
  "tr_TR Localization": "tr_TR Localization",
  "Turkish localization": "Turkish localization",
  "no_NO Localization": "no_NO Localization",
  "Norwegian localization": "Norwegian localization",
  "ru_RU Localization": "ru_RU Localization",
  "Russian localization": "Russian localization",
  "fi_FI Localization": "fi_FI Localization",
  "Finnish localization": "Finnish localization",
  "zh_Hans Localization": "zh_Hans Localization",
  "Simplified Chinese localization.": "Simplified Chinese localization.",
  "old localizations": "old localizations",
  "Old unmaintained localizations that used to be a part of main repository": "Old unmaintained localizations that used to be a part of main repository"
}