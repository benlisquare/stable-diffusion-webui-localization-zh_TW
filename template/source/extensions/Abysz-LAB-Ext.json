{
  "Abysz LAB": "Abysz LAB",
  "Main": "Main",
  "LAB Tools": "LAB Tools",
  "Guide": "Guide",
  "Abysz LAB 0.1.9 Temporal coherence tools": "Abysz LAB 0.1.9 Temporal coherence tools",
  "DFI Render": "DFI Render",
  "Original frames folder": "Original frames folder",
  "Generated frames folder": "Generated frames folder",
  "Output folder": "Output folder",
  "Info": "Info",
  "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.": "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.",
  "Source denoise:": "Source denoise:",
  "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.": "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.",
  "(This is a demanding algorithm)": "(This is a demanding algorithm)",
  "DFI Tolerance:": "DFI Tolerance:",
  "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.": "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.",
  "This parameter commands the new dynamic algorithm.": "This parameter commands the new dynamic algorithm.",
  "DFI Expand:": "DFI Expand:",
  "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.": "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.",
  "Source Denoise": "Source Denoise",
  "DFI Tolerance": "DFI Tolerance",
  "DFI Expand": "DFI Expand",
  "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.": "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.",
  "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).": "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).",
  "Preview DFI Map": "Preview DFI Map",
  "Preview amount. 0 = Quick shoot": "Preview amount. 0 = Quick shoot",
  "Advanced": "Advanced",
  "Inter Denoise:": "Inter Denoise:",
  "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.": "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.",
  "Inter Blur:": "Inter Blur:",
  "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.": "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.",
  "Corruption Refresh:": "Corruption Refresh:",
  "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.": "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.",
  "Corruption Preserve:": "Corruption Preserve:",
  "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.": "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.",
  "Smooth:": "Smooth:",
  "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.": "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.",
  "Inter Denoise": "Inter Denoise",
  "Inter Denoise Size": "Inter Denoise Size",
  "Inter Denoise FPD": "Inter Denoise FPD",
  "Inter Blur": "Inter Blur",
  "The new dynamic algorithm will handle these parameters. Activate them only for manual control.": "The new dynamic algorithm will handle these parameters. Activate them only for manual control.",
  "Corruption Refresh (Lower = Faster)": "Corruption Refresh (Lower = Faster)",
  "Corruption Preserve": "Corruption Preserve",
  "Smooth": "Smooth",
  "Frames to render. 0=ALL": "Frames to render. 0=ALL",
  "Run DFI": "Run DFI",
  "Status": "Status",
  "Show output folder video": "Show output folder video",
  "|": "|",
  "Deflickers Playground": "Deflickers Playground",
  "Frames folder": "Frames folder",
  "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.": "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.",
  "Blend:": "Blend:",
  "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.": "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.",
  "Overlay:": "Overlay:",
  "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.": "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.",
  "Normalize:": "Normalize:",
  "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.": "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.",
  "BLEND (0=Off)": "BLEND (0=Off)",
  "OVERLAY (0=Off)": "OVERLAY (0=Off)",
  "NORMALIZE (0=Off))": "NORMALIZE (0=Off))",
  "Deflickers": "Deflickers",
  "Style Fuse": "Style Fuse",
  "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.": "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.",
  "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.": "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.",
  "Style frames": "Style frames",
  "Video frames": "Video frames",
  "Fuse Strength": "Fuse Strength",
  "Fuse": "Fuse",
  "Video extract": "Video extract",
  "Video path": "Video path",
  "Fps. 0=Original": "Fps. 0=Original",
  "Extract": "Extract",
  "What DFI does?": "What DFI does?",
  "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext": "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext",
  "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.": "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.",
  "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.": "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.",
  "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.": "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.",
  "Usage strategies": "Usage strategies",
  "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.": "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.",
  "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.": "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.",
  "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.": "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.",
  "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.": "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.",
  "Abysz-LAB-Ext": "Abysz-LAB-Ext",
  "https://github.com/AbyszOne/Abysz-LAB-Ext": "https://github.com/AbyszOne/Abysz-LAB-Ext",
  "The RAW frames you have used as base for IA generation.": "The RAW frames you have used as base for IA generation.",
  "The frames of AI generated video": "The frames of AI generated video",
  "Remember that each generation overwrites previous frames in the same folder.": "Remember that each generation overwrites previous frames in the same folder.",
  "STAND BY...": "STAND BY...",
  "Frames to process": "Frames to process",
  "Processed frames": "Processed frames",
  "Style to fuse": "Style to fuse",
  "Remember to use same fps as generated video for DFI": "Remember to use same fps as generated video for DFI"
}
